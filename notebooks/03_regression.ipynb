{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luis\\Documents\\6\\CSRoundPrediction\\data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = DATA_DIR / 'processed' / 'csgo_clean.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clean_data_path, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the data was properly read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122410 entries, 0 to 122409\n",
      "Data columns (total 76 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   time_left                     122410 non-null  float64\n",
      " 1   ct_score                      122410 non-null  float64\n",
      " 2   t_score                       122410 non-null  float64\n",
      " 3   bomb_planted                  122410 non-null  bool   \n",
      " 4   ct_health                     122410 non-null  float64\n",
      " 5   t_health                      122410 non-null  float64\n",
      " 6   ct_armor                      122410 non-null  float64\n",
      " 7   t_armor                       122410 non-null  float64\n",
      " 8   ct_money                      122410 non-null  float64\n",
      " 9   t_money                       122410 non-null  float64\n",
      " 10  ct_helmets                    122410 non-null  float64\n",
      " 11  t_helmets                     122410 non-null  float64\n",
      " 12  ct_defuse_kits                122410 non-null  float64\n",
      " 13  ct_players_alive              122410 non-null  float64\n",
      " 14  t_players_alive               122410 non-null  float64\n",
      " 15  ct_weapon_ak47                122410 non-null  float64\n",
      " 16  t_weapon_ak47                 122410 non-null  float64\n",
      " 17  ct_weapon_aug                 122410 non-null  float64\n",
      " 18  t_weapon_aug                  122410 non-null  float64\n",
      " 19  ct_weapon_awp                 122410 non-null  float64\n",
      " 20  t_weapon_awp                  122410 non-null  float64\n",
      " 21  ct_weapon_cz75auto            122410 non-null  float64\n",
      " 22  t_weapon_cz75auto             122410 non-null  float64\n",
      " 23  ct_weapon_famas               122410 non-null  float64\n",
      " 24  t_weapon_famas                122410 non-null  float64\n",
      " 25  ct_weapon_galilar             122410 non-null  float64\n",
      " 26  t_weapon_galilar              122410 non-null  float64\n",
      " 27  ct_weapon_glock               122410 non-null  float64\n",
      " 28  t_weapon_glock                122410 non-null  float64\n",
      " 29  ct_weapon_m4a1s               122410 non-null  float64\n",
      " 30  ct_weapon_m4a4                122410 non-null  float64\n",
      " 31  t_weapon_m4a4                 122410 non-null  float64\n",
      " 32  ct_weapon_mac10               122410 non-null  float64\n",
      " 33  t_weapon_mac10                122410 non-null  float64\n",
      " 34  ct_weapon_mag7                122410 non-null  float64\n",
      " 35  ct_weapon_mp9                 122410 non-null  float64\n",
      " 36  t_weapon_mp9                  122410 non-null  float64\n",
      " 37  ct_weapon_sg553               122410 non-null  float64\n",
      " 38  t_weapon_sg553                122410 non-null  float64\n",
      " 39  ct_weapon_ssg08               122410 non-null  float64\n",
      " 40  t_weapon_ssg08                122410 non-null  float64\n",
      " 41  ct_weapon_ump45               122410 non-null  float64\n",
      " 42  t_weapon_ump45                122410 non-null  float64\n",
      " 43  ct_weapon_xm1014              122410 non-null  float64\n",
      " 44  ct_weapon_deagle              122410 non-null  float64\n",
      " 45  t_weapon_deagle               122410 non-null  float64\n",
      " 46  ct_weapon_fiveseven           122410 non-null  float64\n",
      " 47  t_weapon_fiveseven            122410 non-null  float64\n",
      " 48  ct_weapon_usps                122410 non-null  float64\n",
      " 49  t_weapon_usps                 122410 non-null  float64\n",
      " 50  ct_weapon_p250                122410 non-null  float64\n",
      " 51  t_weapon_p250                 122410 non-null  float64\n",
      " 52  ct_weapon_p2000               122410 non-null  float64\n",
      " 53  t_weapon_p2000                122410 non-null  float64\n",
      " 54  ct_weapon_tec9                122410 non-null  float64\n",
      " 55  t_weapon_tec9                 122410 non-null  float64\n",
      " 56  ct_grenade_hegrenade          122410 non-null  float64\n",
      " 57  t_grenade_hegrenade           122410 non-null  float64\n",
      " 58  ct_grenade_flashbang          122410 non-null  float64\n",
      " 59  t_grenade_flashbang           122410 non-null  float64\n",
      " 60  ct_grenade_smokegrenade       122410 non-null  float64\n",
      " 61  t_grenade_smokegrenade        122410 non-null  float64\n",
      " 62  ct_grenade_incendiarygrenade  122410 non-null  float64\n",
      " 63  t_grenade_incendiarygrenade   122410 non-null  float64\n",
      " 64  ct_grenade_molotovgrenade     122410 non-null  float64\n",
      " 65  t_grenade_molotovgrenade      122410 non-null  float64\n",
      " 66  ct_grenade_decoygrenade       122410 non-null  float64\n",
      " 67  t_grenade_decoygrenade        122410 non-null  float64\n",
      " 68  round_winner                  122410 non-null  int64  \n",
      " 69  de_dust2                      122410 non-null  bool   \n",
      " 70  de_inferno                    122410 non-null  bool   \n",
      " 71  de_mirage                     122410 non-null  bool   \n",
      " 72  de_nuke                       122410 non-null  bool   \n",
      " 73  de_overpass                   122410 non-null  bool   \n",
      " 74  de_train                      122410 non-null  bool   \n",
      " 75  de_vertigo                    122410 non-null  bool   \n",
      "dtypes: bool(8), float64(67), int64(1)\n",
      "memory usage: 64.4 MB\n"
     ]
    }
   ],
   "source": [
    "model_data = data.copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into be split into 2 sets: training and testing. The training set will be used to train the model and the testing set will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop(columns=['round_winner']).copy()\n",
    "y = model_data['round_winner'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the test set with 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the train and validation sets with 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78342, 75), (19586, 75), (24482, 75))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_quality(model,x_val, y_val):\n",
    "    y_predicted = model.predict(x_val)\n",
    "    accuracy = accuracy_score(y_val, y_predicted)\n",
    "    f1 = f1_score(y_val, y_predicted)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.75 But it doesn't converge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1750\n",
    "                           )\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.81\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=60,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.85\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=75, \n",
    "    learning_rate=0.8, \n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.75\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was sugested by the professor, and it's idea is to split the data into several parts. Then, going through chunks of three parts, three models are trained and the majority vote is taken as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow is a showcase of the model. Using just 1 split, the data will not be split into chunks, and the result should be the same as the \n",
    "[RandomForestClassifier](#randomforestclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self.parts:\n",
      "Part 0 size: (78342, 76), time_left: 175.0 - 0.03\n",
      "Accuracy: 0.87\n",
      "F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "model_used = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, n_splits=1)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "# model_used = RandomForestClassifier(random_state=42, max_depth=25, n_estimators=100)\n",
    "model_used = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, 5)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MiniModels\n",
    "from sklearn import tree\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "model_used = tree.DecisionTreeClassifier(random_state=42, max_depth=20)\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, 5)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "model_used = GradientBoostingClassifier(\n",
    "    n_estimators=75, \n",
    "    learning_rate=0.8, \n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, 5)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_depth': 50, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.8706396765874642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(x_train_val, y_train_val)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluating the best model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=50,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train_val, y_train_val)\n",
    "calculate_model_quality(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evualating model quality using a DummyClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round_winner\n",
      "0    49928\n",
      "1    48000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Most frequent class\n",
    "most_frequent_class = y_train_val.value_counts()\n",
    "print(most_frequent_class) # Print the Distribution of the classes\n",
    "\n",
    "# Get the most frequent class\n",
    "most_frequent_class = most_frequent_class.idxmax()\n",
    "\n",
    "# Create an array with the same shape as y_test and fill it with the most frequent class\n",
    "y_predicted = np.full_like(y_test, fill_value=most_frequent_class)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print()\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model was certified with 0.88 accuracy and beat the DummyClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the elected model, the data will be trained again, but now with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(X, y) # Train the model with the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = DATA_DIR / 'models' / 'csgo_model.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
