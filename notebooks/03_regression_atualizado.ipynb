{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luis\\Documents\\6\\CSRoundPrediction\\data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = DATA_DIR / 'processed' / 'csgo_clean.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clean_data_path, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the data was properly read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122410 entries, 0 to 122409\n",
      "Data columns (total 76 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   time_left                     122410 non-null  float64\n",
      " 1   ct_score                      122410 non-null  float64\n",
      " 2   t_score                       122410 non-null  float64\n",
      " 3   bomb_planted                  122410 non-null  bool   \n",
      " 4   ct_health                     122410 non-null  float64\n",
      " 5   t_health                      122410 non-null  float64\n",
      " 6   ct_armor                      122410 non-null  float64\n",
      " 7   t_armor                       122410 non-null  float64\n",
      " 8   ct_money                      122410 non-null  float64\n",
      " 9   t_money                       122410 non-null  float64\n",
      " 10  ct_helmets                    122410 non-null  float64\n",
      " 11  t_helmets                     122410 non-null  float64\n",
      " 12  ct_defuse_kits                122410 non-null  float64\n",
      " 13  ct_players_alive              122410 non-null  float64\n",
      " 14  t_players_alive               122410 non-null  float64\n",
      " 15  ct_weapon_ak47                122410 non-null  float64\n",
      " 16  t_weapon_ak47                 122410 non-null  float64\n",
      " 17  ct_weapon_aug                 122410 non-null  float64\n",
      " 18  t_weapon_aug                  122410 non-null  float64\n",
      " 19  ct_weapon_awp                 122410 non-null  float64\n",
      " 20  t_weapon_awp                  122410 non-null  float64\n",
      " 21  ct_weapon_cz75auto            122410 non-null  float64\n",
      " 22  t_weapon_cz75auto             122410 non-null  float64\n",
      " 23  ct_weapon_famas               122410 non-null  float64\n",
      " 24  t_weapon_famas                122410 non-null  float64\n",
      " 25  ct_weapon_galilar             122410 non-null  float64\n",
      " 26  t_weapon_galilar              122410 non-null  float64\n",
      " 27  ct_weapon_glock               122410 non-null  float64\n",
      " 28  t_weapon_glock                122410 non-null  float64\n",
      " 29  ct_weapon_m4a1s               122410 non-null  float64\n",
      " 30  ct_weapon_m4a4                122410 non-null  float64\n",
      " 31  t_weapon_m4a4                 122410 non-null  float64\n",
      " 32  ct_weapon_mac10               122410 non-null  float64\n",
      " 33  t_weapon_mac10                122410 non-null  float64\n",
      " 34  ct_weapon_mag7                122410 non-null  float64\n",
      " 35  ct_weapon_mp9                 122410 non-null  float64\n",
      " 36  t_weapon_mp9                  122410 non-null  float64\n",
      " 37  ct_weapon_sg553               122410 non-null  float64\n",
      " 38  t_weapon_sg553                122410 non-null  float64\n",
      " 39  ct_weapon_ssg08               122410 non-null  float64\n",
      " 40  t_weapon_ssg08                122410 non-null  float64\n",
      " 41  ct_weapon_ump45               122410 non-null  float64\n",
      " 42  t_weapon_ump45                122410 non-null  float64\n",
      " 43  ct_weapon_xm1014              122410 non-null  float64\n",
      " 44  ct_weapon_deagle              122410 non-null  float64\n",
      " 45  t_weapon_deagle               122410 non-null  float64\n",
      " 46  ct_weapon_fiveseven           122410 non-null  float64\n",
      " 47  t_weapon_fiveseven            122410 non-null  float64\n",
      " 48  ct_weapon_usps                122410 non-null  float64\n",
      " 49  t_weapon_usps                 122410 non-null  float64\n",
      " 50  ct_weapon_p250                122410 non-null  float64\n",
      " 51  t_weapon_p250                 122410 non-null  float64\n",
      " 52  ct_weapon_p2000               122410 non-null  float64\n",
      " 53  t_weapon_p2000                122410 non-null  float64\n",
      " 54  ct_weapon_tec9                122410 non-null  float64\n",
      " 55  t_weapon_tec9                 122410 non-null  float64\n",
      " 56  ct_grenade_hegrenade          122410 non-null  float64\n",
      " 57  t_grenade_hegrenade           122410 non-null  float64\n",
      " 58  ct_grenade_flashbang          122410 non-null  float64\n",
      " 59  t_grenade_flashbang           122410 non-null  float64\n",
      " 60  ct_grenade_smokegrenade       122410 non-null  float64\n",
      " 61  t_grenade_smokegrenade        122410 non-null  float64\n",
      " 62  ct_grenade_incendiarygrenade  122410 non-null  float64\n",
      " 63  t_grenade_incendiarygrenade   122410 non-null  float64\n",
      " 64  ct_grenade_molotovgrenade     122410 non-null  float64\n",
      " 65  t_grenade_molotovgrenade      122410 non-null  float64\n",
      " 66  ct_grenade_decoygrenade       122410 non-null  float64\n",
      " 67  t_grenade_decoygrenade        122410 non-null  float64\n",
      " 68  round_winner                  122410 non-null  int64  \n",
      " 69  de_dust2                      122410 non-null  bool   \n",
      " 70  de_inferno                    122410 non-null  bool   \n",
      " 71  de_mirage                     122410 non-null  bool   \n",
      " 72  de_nuke                       122410 non-null  bool   \n",
      " 73  de_overpass                   122410 non-null  bool   \n",
      " 74  de_train                      122410 non-null  bool   \n",
      " 75  de_vertigo                    122410 non-null  bool   \n",
      "dtypes: bool(8), float64(67), int64(1)\n",
      "memory usage: 64.4 MB\n"
     ]
    }
   ],
   "source": [
    "model_data = data.copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into be split into 2 sets: training and testing. The training set will be used to train the model and the testing set will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop(columns=['round_winner']).copy()\n",
    "y = model_data['round_winner'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the test set with 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the train and validation sets with 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78342, 75), (19586, 75), (24482, 75))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_quality(model,x_val, y_val):\n",
    "    y_predicted = model.predict(x_val)\n",
    "    accuracy = accuracy_score(y_val, y_predicted)\n",
    "    f1 = f1_score(y_val, y_predicted)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "F1: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis/Documents/6/ml/CSRoundPrediction/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 0.75 Mas não converge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=750\n",
    "                           )\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=60,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "F1: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=75, \n",
    "    learning_rate=0.8, \n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "F1: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was sugested by the professor, and it's idea is to split the data into several parts and train a model for each part. The model will be trained with a different part of the data, and the prediction will be a combination of the predictions of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete = pd.concat([x_train, y_train], axis=1)\n",
    "val_complete = pd.concat([x_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0 size: 15668, most common class: 1, time range: 174.91 - 175.0\n",
      "Part 1 size: 15668, most common class: 1, time range: 107.19 - 174.91\n",
      "Part 2 size: 15668, most common class: 1, time range: 74.95 - 107.18\n",
      "Part 3 size: 15668, most common class: 1, time range: 39.45 - 74.95\n",
      "Part 4 size: 15670, most common class: 0, time range: 0.03 - 39.45\n"
     ]
    }
   ],
   "source": [
    "# Define the number of parts to split the dataset into\n",
    "num_parts = 5\n",
    "\n",
    "# Calculate the size of each part\n",
    "part_size = len(train_complete) // num_parts\n",
    "\n",
    "# Sort the dataset by the 'time_left' column\n",
    "train_complete_sorted = train_complete.sort_values(by='time_left', ascending=False)\n",
    "\n",
    "# Split the dataset into equal parts\n",
    "parts = [train_complete_sorted.iloc[i*part_size:(i+1)*part_size] for i in range(num_parts)]\n",
    "\n",
    "# If there are any remaining rows, add them to the last part\n",
    "if len(train_complete) % num_parts != 0:\n",
    "    parts[-1] = pd.concat([parts[-1], train_complete_sorted.iloc[num_parts*part_size:]])\n",
    "\n",
    "# Display the size of each part\n",
    "for i, part in enumerate(parts):\n",
    "    print(f\"Part {i} size: {len(part)}, most common class: {part['round_winner'].value_counts().idxmax()}, time range: {part['time_left'].min()} - {part['time_left'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0 size: 15668, time_left: 175.0 - 174.91\n",
      "Part 1 size: 15668, time_left: 174.91 - 107.19\n",
      "Part 2 size: 15668, time_left: 107.18 - 74.95\n",
      "Part 3 size: 15668, time_left: 74.95 - 39.45\n",
      "Part 4 size: 15670, time_left: 39.45 - 0.03\n"
     ]
    }
   ],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = MiniModels.MiniModels()\n",
    "\n",
    "model.fit(x_train, y_train, RandomForestClassifier, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
