{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luis\\Documents\\6\\CSRoundPrediction\\data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = DATA_DIR / 'processed' / 'csgo_clean.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clean_data_path, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the data was properly read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122410 entries, 0 to 122409\n",
      "Data columns (total 76 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   time_left                     122410 non-null  float64\n",
      " 1   ct_score                      122410 non-null  float64\n",
      " 2   t_score                       122410 non-null  float64\n",
      " 3   bomb_planted                  122410 non-null  bool   \n",
      " 4   ct_health                     122410 non-null  float64\n",
      " 5   t_health                      122410 non-null  float64\n",
      " 6   ct_armor                      122410 non-null  float64\n",
      " 7   t_armor                       122410 non-null  float64\n",
      " 8   ct_money                      122410 non-null  float64\n",
      " 9   t_money                       122410 non-null  float64\n",
      " 10  ct_helmets                    122410 non-null  float64\n",
      " 11  t_helmets                     122410 non-null  float64\n",
      " 12  ct_defuse_kits                122410 non-null  float64\n",
      " 13  ct_players_alive              122410 non-null  float64\n",
      " 14  t_players_alive               122410 non-null  float64\n",
      " 15  ct_weapon_ak47                122410 non-null  float64\n",
      " 16  t_weapon_ak47                 122410 non-null  float64\n",
      " 17  ct_weapon_aug                 122410 non-null  float64\n",
      " 18  t_weapon_aug                  122410 non-null  float64\n",
      " 19  ct_weapon_awp                 122410 non-null  float64\n",
      " 20  t_weapon_awp                  122410 non-null  float64\n",
      " 21  ct_weapon_cz75auto            122410 non-null  float64\n",
      " 22  t_weapon_cz75auto             122410 non-null  float64\n",
      " 23  ct_weapon_famas               122410 non-null  float64\n",
      " 24  t_weapon_famas                122410 non-null  float64\n",
      " 25  ct_weapon_galilar             122410 non-null  float64\n",
      " 26  t_weapon_galilar              122410 non-null  float64\n",
      " 27  ct_weapon_glock               122410 non-null  float64\n",
      " 28  t_weapon_glock                122410 non-null  float64\n",
      " 29  ct_weapon_m4a1s               122410 non-null  float64\n",
      " 30  ct_weapon_m4a4                122410 non-null  float64\n",
      " 31  t_weapon_m4a4                 122410 non-null  float64\n",
      " 32  ct_weapon_mac10               122410 non-null  float64\n",
      " 33  t_weapon_mac10                122410 non-null  float64\n",
      " 34  ct_weapon_mag7                122410 non-null  float64\n",
      " 35  ct_weapon_mp9                 122410 non-null  float64\n",
      " 36  t_weapon_mp9                  122410 non-null  float64\n",
      " 37  ct_weapon_sg553               122410 non-null  float64\n",
      " 38  t_weapon_sg553                122410 non-null  float64\n",
      " 39  ct_weapon_ssg08               122410 non-null  float64\n",
      " 40  t_weapon_ssg08                122410 non-null  float64\n",
      " 41  ct_weapon_ump45               122410 non-null  float64\n",
      " 42  t_weapon_ump45                122410 non-null  float64\n",
      " 43  ct_weapon_xm1014              122410 non-null  float64\n",
      " 44  ct_weapon_deagle              122410 non-null  float64\n",
      " 45  t_weapon_deagle               122410 non-null  float64\n",
      " 46  ct_weapon_fiveseven           122410 non-null  float64\n",
      " 47  t_weapon_fiveseven            122410 non-null  float64\n",
      " 48  ct_weapon_usps                122410 non-null  float64\n",
      " 49  t_weapon_usps                 122410 non-null  float64\n",
      " 50  ct_weapon_p250                122410 non-null  float64\n",
      " 51  t_weapon_p250                 122410 non-null  float64\n",
      " 52  ct_weapon_p2000               122410 non-null  float64\n",
      " 53  t_weapon_p2000                122410 non-null  float64\n",
      " 54  ct_weapon_tec9                122410 non-null  float64\n",
      " 55  t_weapon_tec9                 122410 non-null  float64\n",
      " 56  ct_grenade_hegrenade          122410 non-null  float64\n",
      " 57  t_grenade_hegrenade           122410 non-null  float64\n",
      " 58  ct_grenade_flashbang          122410 non-null  float64\n",
      " 59  t_grenade_flashbang           122410 non-null  float64\n",
      " 60  ct_grenade_smokegrenade       122410 non-null  float64\n",
      " 61  t_grenade_smokegrenade        122410 non-null  float64\n",
      " 62  ct_grenade_incendiarygrenade  122410 non-null  float64\n",
      " 63  t_grenade_incendiarygrenade   122410 non-null  float64\n",
      " 64  ct_grenade_molotovgrenade     122410 non-null  float64\n",
      " 65  t_grenade_molotovgrenade      122410 non-null  float64\n",
      " 66  ct_grenade_decoygrenade       122410 non-null  float64\n",
      " 67  t_grenade_decoygrenade        122410 non-null  float64\n",
      " 68  round_winner                  122410 non-null  int64  \n",
      " 69  de_dust2                      122410 non-null  bool   \n",
      " 70  de_inferno                    122410 non-null  bool   \n",
      " 71  de_mirage                     122410 non-null  bool   \n",
      " 72  de_nuke                       122410 non-null  bool   \n",
      " 73  de_overpass                   122410 non-null  bool   \n",
      " 74  de_train                      122410 non-null  bool   \n",
      " 75  de_vertigo                    122410 non-null  bool   \n",
      "dtypes: bool(8), float64(67), int64(1)\n",
      "memory usage: 64.4 MB\n"
     ]
    }
   ],
   "source": [
    "model_data = data.copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into be split into 2 sets: training and testing. The training set will be used to train the model and the testing set will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop(columns=['round_winner']).copy()\n",
    "y = model_data['round_winner'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the test set with 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the train and validation sets with 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78342, 75), (19586, 75), (24482, 75))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_quality(model,x_val, y_val):\n",
    "    y_predicted = model.predict(x_val)\n",
    "    accuracy = accuracy_score(y_val, y_predicted)\n",
    "    f1 = f1_score(y_val, y_predicted)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.75 But it doesn't converge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1750\n",
    "                           )\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.81\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=60,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.85\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=75, \n",
    "    learning_rate=0.8, \n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.75\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was sugested by the professor, and it's idea is to split the data into several parts. Then, going through chunks of three parts, three models are trained and the majority vote is taken as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow is a showcase of the model. Using just 1 split, the data will not be split into chunks, and the result should be the same as the \n",
    "[RandomForestClassifier](#randomforestclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self.parts:\n",
      "Part 0 size: (78342, 76), time_left: 175.0 - 0.03\n",
      "Accuracy: 0.87\n",
      "F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "model_used = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, n_splits=1)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "# model_used = RandomForestClassifier(random_state=42, max_depth=25, n_estimators=100)\n",
    "model_used = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, 5)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MiniModels\n",
    "from sklearn import tree\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "model_used = tree.DecisionTreeClassifier(random_state=42, max_depth=20)\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, 5)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MiniModels\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "Splitmodel = MiniModels.MiniModels()\n",
    "model_used = GradientBoostingClassifier(\n",
    "    n_estimators=75, \n",
    "    learning_rate=0.8, \n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "Splitmodel.fit(x_train, y_train, model_used, 5)\n",
    "calculate_model_quality(Splitmodel, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "calculate_model_quality(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_depth': 50, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.8706396765874642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(x_train_val, y_train_val)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluating the best model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "# 0.87 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=50,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(x_train_val, y_train_val)\n",
    "calculate_model_quality(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evualating model quality using a DummyClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round_winner\n",
      "0    49928\n",
      "1    48000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Most frequent class\n",
    "most_frequent_class = y_train_val.value_counts()\n",
    "print(most_frequent_class) # Print the Distribution of the classes\n",
    "\n",
    "# Get the most frequent class\n",
    "most_frequent_class = most_frequent_class.idxmax()\n",
    "\n",
    "# Create an array with the same shape as y_test and fill it with the most frequent class\n",
    "y_predicted = np.full_like(y_test, fill_value=most_frequent_class)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print()\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model was certified with 0.88 accuracy and beat the DummyClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the elected model, the data will be trained again, but now with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    ")\n",
    "\n",
    "model.fit(X, y) # Train the model with the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = DATA_DIR / 'models' / 'csgo_model.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test just the deployment, run the cell bellow to import the necessary libraries and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
    "model_path = DATA_DIR / 'models' / 'csgo_model.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow is necessary to create auxiliar functions and classes that will be used to organize the data before making the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchData:\n",
    "    def __init__(self, time_left, ct_score, t_score, map, bomb_planted, ct_defuse_kits, ct_health, t_health, ct_armor, t_armor, ct_helmets, t_helmets, ct_money, t_money, ct_players_alive, t_players_alive, ct_weapons, t_weapons):\n",
    "        self.time_left = time_left\n",
    "        self.ct_score = ct_score\n",
    "        self.t_score = t_score\n",
    "        self.map = map\n",
    "        self.bomb_planted = bomb_planted\n",
    "        self.ct_defuse_kits = ct_defuse_kits\n",
    "        self.ct_health = ct_health\n",
    "        self.t_health = t_health\n",
    "        self.ct_armor = ct_armor\n",
    "        self.t_armor = t_armor\n",
    "        self.ct_helmets = ct_helmets\n",
    "        self.t_helmets = t_helmets\n",
    "        self.ct_money = ct_money\n",
    "        self.t_money = t_money\n",
    "        self.ct_players_alive = ct_players_alive\n",
    "        self.t_players_alive = t_players_alive\n",
    "        self.ct_weapons = ct_weapons\n",
    "        self.t_weapons = t_weapons\n",
    "\n",
    "# List of all possible features\n",
    "ALL_FEATURES = [\n",
    "    \"time_left\", \"ct_score\", \"t_score\", \"bomb_planted\", \"ct_health\", \"t_health\", \"ct_armor\", \"t_armor\", \"ct_money\", \"t_money\", \"ct_helmets\", \"t_helmets\",\n",
    "    \"ct_defuse_kits\", \"ct_players_alive\", \"t_players_alive\", \"ct_weapon_ak47\", \"t_weapon_ak47\", \"ct_weapon_aug\", \"t_weapon_aug\", \"ct_weapon_awp\", \"t_weapon_awp\", \"ct_weapon_cz75auto\", \"t_weapon_cz75auto\", \"ct_weapon_famas\",\n",
    "    \"t_weapon_famas\", \"ct_weapon_galilar\", \"t_weapon_galilar\", \"ct_weapon_glock\", \"t_weapon_glock\", \"ct_weapon_m4a1s\", \"ct_weapon_m4a4\", \"t_weapon_m4a4\", \"ct_weapon_mac10\", \"t_weapon_mac10\", \"ct_weapon_mag7\", \"ct_weapon_mp9\",\n",
    "    \"t_weapon_mp9\", \"ct_weapon_sg553\", \"t_weapon_sg553\", \"ct_weapon_ssg08\", \"t_weapon_ssg08\", \"ct_weapon_ump45\", \"t_weapon_ump45\", \"ct_weapon_xm1014\", \"ct_weapon_deagle\", \"t_weapon_deagle\", \"ct_weapon_fiveseven\", \"t_weapon_fiveseven\", \"ct_weapon_usps\", \"t_weapon_usps\", \"ct_weapon_p250\",\n",
    "    \"t_weapon_p250\", \"ct_weapon_p2000\", \"t_weapon_p2000\", \"ct_weapon_tec9\", \"t_weapon_tec9\", \"ct_grenade_hegrenade\", \"t_grenade_hegrenade\", \"ct_grenade_flashbang\", \"t_grenade_flashbang\", \"ct_grenade_smokegrenade\",\n",
    "    \"t_grenade_smokegrenade\", \"ct_grenade_incendiarygrenade\", \"t_grenade_incendiarygrenade\", \"ct_grenade_molotovgrenade\", \"t_grenade_molotovgrenade\", \"ct_grenade_decoygrenade\", \"t_grenade_decoygrenade\", \"de_dust2\", \"de_inferno\", \"de_mirage\",\n",
    "    \"de_nuke\", \"de_overpass\", \"de_train\", \"de_vertigo\"\n",
    "]\n",
    "\n",
    "def match_data_to_dataframe(features: MatchData) -> pd.DataFrame:\n",
    "    # Create a DataFrame using the ALL_FEATURES list as columns. Fill the DataFrame with zeros\n",
    "    data = pd.DataFrame(0, index=[0], columns=ALL_FEATURES)\n",
    "\n",
    "    # Set the values of the features that we know\n",
    "    data[\"time_left\"] = features.time_left\n",
    "    data[\"ct_score\"] = features.ct_score\n",
    "    data[\"t_score\"] = features.t_score\n",
    "    data[\"bomb_planted\"] = features.bomb_planted\n",
    "    data[\"ct_defuse_kits\"] = features.ct_defuse_kits\n",
    "    data[\"ct_health\"] = features.ct_health\n",
    "    data[\"t_health\"] = features.t_health\n",
    "    data[\"ct_armor\"] = features.ct_armor\n",
    "    data[\"t_armor\"] = features.t_armor\n",
    "    data[\"ct_helmets\"] = features.ct_helmets\n",
    "    data[\"t_helmets\"] = features.t_helmets\n",
    "    data[\"ct_money\"] = features.ct_money\n",
    "    data[\"t_money\"] = features.t_money\n",
    "    data[\"ct_players_alive\"] = features.ct_players_alive\n",
    "    data[\"t_players_alive\"] = features.t_players_alive\n",
    "\n",
    "    # Iterate through the weapons and add 1 to the corresponding column\n",
    "    for weapon in features.ct_weapons:\n",
    "        if weapon in data.columns:\n",
    "            data[weapon] += 1\n",
    "\n",
    "    for weapon in features.t_weapons:\n",
    "        if weapon in data.columns:\n",
    "            data[weapon] += 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickel model\n",
    "with open(model_path, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example, we will use the Grand Final Match of the 2020 Counter Strike Global Offensive Major. \n",
    "Which can be found [here](https://www.youtube.com/watch?v=NOuvxSHu74o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the winner of one round of the match. We will calculate the winner on 3 moments of the round, and check how the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first Scene we have the following situation:\n",
    "\n",
    "<img src=\"../imgs/firstScene.png\" alt=\"First Scene\" style=\"max-width: 60%; height: auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scene was captured at the begginning of the round, when the players are still in their spawn areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terrrorists win\n"
     ]
    }
   ],
   "source": [
    "features = MatchData(\n",
    "    time_left=90,\n",
    "    ct_score=8,\n",
    "    t_score=0,\n",
    "    map=\"de_nuke\",\n",
    "    bomb_planted=False,\n",
    "    ct_defuse_kits=5,\n",
    "    ct_health=500, # 5 players with 100 health\n",
    "    t_health=500, # 5 players with 100 health\n",
    "    ct_armor=500, # 5 players with 100 armor\n",
    "    t_armor=500,\n",
    "    ct_helmets=5, # All players have helmets \n",
    "    t_helmets=5,\n",
    "    ct_money=29950,\n",
    "    t_money=5100,\n",
    "    ct_players_alive=5,\n",
    "    t_players_alive=5,\n",
    "    ct_weapons=[\"ct_weapon_m4a4\",\"ct_weapon_m4a4\",\"ct_weapon_ak47\", \"ct_weapon_m4a4\", \"ct_weapon_awp\"], # 3 M4A4, 1 AK47, 1 AWP \n",
    "    t_weapons=[\"t_weapon_ak47\",\"t_weapon_awp\",\"t_weapon_ak47\", \"t_weapon_ak47\", \"t_weapon_sg553\"]  # 3 AK47, 1 AWP, 1 SG553  \n",
    "                                                                                                    # These are the main weapons that the players are using in this moment of the round\n",
    ")\n",
    "\n",
    "df = match_data_to_dataframe(features)\n",
    "\n",
    "# Predict the outcome of the round\n",
    "prediction = model.predict(df)\n",
    "print(\"Terrrorists win\" if prediction[0] == 0 else \"Counter-Teorrist win\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's predict the winner of the same round, but in a different moment. At this moment the players are already in the bombsite, and the bomb is being planted. There was already losses on both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second Scene we have the following situation:\n",
    "\n",
    "<img src=\"../imgs/secondScene.png\" alt=\"Second Scene\" style=\"max-width: 60%; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terrrorists win\n"
     ]
    }
   ],
   "source": [
    "features2 = MatchData(\n",
    "    time_left=40, # 40 seconds left, bomb was just planted \n",
    "    ct_score=8,\n",
    "    t_score=0,\n",
    "    map=\"de_nuke\",\n",
    "    bomb_planted=True,\n",
    "    ct_defuse_kits=3,\n",
    "    ct_health=300, # 3 players with 100 health\n",
    "    t_health=11+39+100+88, # Players already took some damage, thus have different health values\n",
    "    ct_armor=300, # 3 players with 100 armor\n",
    "    t_armor=400, # 4 players with 100 armor\n",
    "    ct_helmets=3, # 3 players left with helmets \n",
    "    t_helmets=5,\n",
    "    ct_money=29950,\n",
    "    t_money=5100,\n",
    "    ct_players_alive=4,\n",
    "    t_players_alive=3,\n",
    "    ct_weapons=[\"ct_weapon_m4a4\",\"ct_weapon_ak47\",\"ct_weapon_m4a4\"], \n",
    "    t_weapons=[\"t_weapon_ak47\",\"t_weapon_awp\", \"t_weapon_ak47\", \"t_weapon_sg553\"]\n",
    "\n",
    ")\n",
    "\n",
    "df = match_data_to_dataframe(features2)\n",
    "\n",
    "# Predict the outcome of the round\n",
    "prediction = model.predict(df)\n",
    "print(\"Terrrorists win\" if prediction[0] == 0 else \"Counter-Teorrist win\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cenario above, the model again predicted the winner of the round as the T side.\n",
    "\n",
    "Now for the third and final scene, we have the following situation:\n",
    "\n",
    "<img src=\"../imgs/thirdScene.png\" alt=\"Third Scene\" style=\"max-width: 60%; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terrrorists win\n"
     ]
    }
   ],
   "source": [
    "features3 = MatchData(\n",
    "    time_left=20, # \n",
    "    ct_score=8,\n",
    "    t_score=0,\n",
    "    map=\"de_nuke\",\n",
    "    bomb_planted=True,\n",
    "    ct_defuse_kits=3,\n",
    "    ct_health=8+100+100, # 3 players with 100 health\n",
    "    t_health=11+39+88, # Players already took some damage, thus have different health values\n",
    "    ct_armor=300, # 3 players with 100 armor\n",
    "    t_armor=300, # 3 players with 100 armor\n",
    "    ct_helmets=3, # 3 players left with helmets \n",
    "    t_helmets=3,\n",
    "    ct_money=29950,\n",
    "    t_money=5100,\n",
    "    ct_players_alive=3,\n",
    "    t_players_alive=3,\n",
    "    ct_weapons=[\"ct_weapon_m4a4\",\"ct_weapon_ak47\",\"ct_weapon_m4a4\"], \n",
    "    t_weapons=[\"t_weapon_ak47\",\"t_weapon_awp\", \"t_weapon_ak47\", \"t_weapon_sg553\"]\n",
    "\n",
    ")\n",
    "\n",
    "df = match_data_to_dataframe(features3)\n",
    "\n",
    "# Predict the outcome of the round\n",
    "prediction = model.predict(df)\n",
    "print(\"Terrrorists win\" if prediction[0] == 0 else \"Counter-Teorrist win\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the round was the same as the model predicted. The T side won the round.\n",
    "\n",
    "<img src=\"../imgs/result.png\" alt=\"Third Scene\" style=\"max-width: 60%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result was consistent with the previous predictions, and the model predicted the T side ( Ilustrated as the orange side in the image) as the winner of the round. The last two scenes make clear the advantage of the T side at the moment of the prediction. So the model was able to predict the winner of the round with a good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a final analyse of the model, let`s check another map of the same match (The finals are decided on a best of 5 maps). The second map of the match was played on the map dust 2. The image below ilustrates the situation of the round at the moment of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/otherRound.png\" alt=\"Inferno\" style=\"max-width: 60%; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter-Teorrist win\n"
     ]
    }
   ],
   "source": [
    "features4 = MatchData(\n",
    "    time_left=50, # \n",
    "    ct_score=5,\n",
    "    t_score=2,\n",
    "    map=\"de_dust2\",\n",
    "    bomb_planted=False,\n",
    "    ct_defuse_kits=0,\n",
    "    ct_health=100+100+100, # 3 players with 100 health\n",
    "    t_health=100+100, # 2 players with 100 health\n",
    "    ct_armor=300, # 3 players with 100 armor\n",
    "    t_armor=200, # 2 players with 100 armor\n",
    "    ct_helmets=3, # 3 players left with helmets \n",
    "    t_helmets=2,\n",
    "    ct_money=400+450+200,\n",
    "    t_money=0+1400,\n",
    "    ct_players_alive=3,\n",
    "    t_players_alive=2,\n",
    "    ct_weapons=[\"ct_weapon_m4a4\",\"ct_weapon_m4a4\",\"ct_weapon_awp\"], # These are the main weapons that the players are using in this moment of the round\n",
    "    t_weapons=[\"t_weapon_galilar\",\"t_weapon_awp\"] # These are the main weapons that the players are using in this moment of the round\n",
    "\n",
    ")\n",
    "\n",
    "df = match_data_to_dataframe(features4)\n",
    "\n",
    "# Predict the outcome of the round\n",
    "prediction = model.predict(df)\n",
    "print(\"Terrrorists win\" if prediction[0] == 0 else \"Counter-Teorrist win\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction of Counter Terrorist side as the winner of the round was correct. The result of the round was the same as the model predicted and it's ilustrated on the image below (Showing the Counter-Terrorist as the blue side).\n",
    "\n",
    "<img src=\"../imgs/End.png\" alt=\"Inferno\" style=\"max-width: 60%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more prediction use this [website](https://prediction.fernandoa.dev/), which shows a dashboard allows the user to make a prediction of a Round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Consideration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The research conducted by the students represents a comprehensive investigation into the dynamics of Counter Strike: Global Offensive (CS:GO). The students successfully identified and eliminated irrelevant features and were able to find and train a model to predict the winner of a Round.\n",
    "\n",
    "The trained model got satisfactory results, suggesting that it can effectively predict specific outcomes based on game behaviors. This indicates that the features chosen and the model configuration were aligned with the underlying patterns of the game, enabling a reasonable level of accuracy in its predictions.\n",
    "\n",
    "While the modelâ€™s performance is promising, it should be noted that the dynamic nature of human interaction in games like CS:GO means that real-world results may vary from the model's predictions.\n",
    "Counter Strike, being a human-played game, involves complexities and unpredictable behaviors that may not always be captured accurately by a machine learning model. Human players often introduce elements of randomness, which can differ from the scenarios the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
